{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For introduction and problem statement, please refer to notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook 1: 1_cellphones_reviews_data_cleaning_and_eda**\n",
    "- Data Import and Cleaning\n",
    "- Exploratory Data Analysis\n",
    "- Text Data Pre-processing\n",
    "\n",
    "**Notebook 2: 2_cellphones_reviews_topic modelling**\n",
    "- Data Import\n",
    "- Topic Modelling with Gensim\n",
    "\n",
    "**Notebook 3: 3_cellphones_reviews_topic_analysis_and_visualizations**\n",
    "- Findings and Analysis of Topic Modelling\n",
    "\n",
    "**Notebook 4: 4_features_extractions_and_sentiment_analysis**\n",
    "- [Data Import](#Data-Import)\n",
    "- [Sentiment Analysis with VADER](#Sentiment-Analysis-with-VADER)\n",
    "- [entiment Analysis with Logistic Regression(Multi-Class Classification)](#Sentiment-Analysis-with-Logistic-Regression-Classifier)\n",
    "- [Evaluation of Sentiment Analysis with BERT(Multi-Class Classification)](#Evaluation-of-Sentiment-Analysis-with-BERT)   \n",
    "Please refer to notebook 5 for the fine-tuning process of pre-trained BERT model\n",
    "\n",
    "**Notebook 5: 5_fine_tuning_of_BERT_model**   \n",
    "The reason why this notebook is separated from notebook 4 which contains the evaluation of BERT model is because the fine-tuning of BERT model requires GPU. Hence, the model was fine-tuned on Google Colaboratory and loaded back into notebook 4 for evaluation\n",
    "\n",
    "\n",
    "**Notebook 6: 6_analysis_and_findings**\n",
    "- Comparison of the 3 Methods \n",
    "- Recommendation and Conclusion \n",
    "- Future Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spacy\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "new_reviews = pd.read_csv('../data/cleaned_combined_data.csv',na_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "#instantiate vader sentiment analyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new word to the lexicon\n",
    "new_words = {\n",
    "    'new': 3.0\n",
    "}\n",
    "\n",
    "analyser.lexicon.update(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the stop words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove negation words from stop words as they are useful context for sentiment predictions\n",
    "negation_words = ['ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \n",
    "\"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", \n",
    "'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", \n",
    "'wouldn', \"wouldn't\",\"not\",\"no\",'don',\"don't\"]\n",
    "\n",
    "for word in negation_words:\n",
    "    stop_words.remove(word)\n",
    "\n",
    "#confirm that the negation words have been removed\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity sake, we are limiting the scope of this project to the keywords defined below:\n",
    "camera, screen, battery, simcard, touchscreen, fingerprint, ringtones and charger as those are the dominant words found in topic modelling. However, after looking through a lot of reviews, there are other keywords like facial recognition, price etc which we may want to include in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_with_keywords (reviews):\n",
    "    \"\"\"\n",
    "    Find only the sentences with keywords. keywords have been pre-defined in this function\n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    reviews:a string of words \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summary: sentences that contained keywords defined below\n",
    "    \"\"\"\n",
    "    list_of_keywords = ['camera','screen','battery','simcard','touchscreen','fingerprint','ringtones','charger']\n",
    "    summary = set()\n",
    "    texts = tokenize.sent_tokenize(reviews)\n",
    "    for sentence in texts:\n",
    "        sentence = sentence.lower()\n",
    "        for word in list_of_keywords:\n",
    "            if word in sentence:\n",
    "                summary.add(sentence)\n",
    "                \n",
    "    return list(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_reviews (reviews):\n",
    "    \"\"\"\n",
    "    Find sentences with keywords, followed by cleaning by removing html, non letter words, stopwords and lemmatizing\n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    reviews:a string of words \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summary: processed sentences that contained keywords defined below\n",
    "    \"\"\"\n",
    "    list_of_keywords = ['camera','screen','battery','simcard','touchscreen','fingerprint','ringtones','charger']\n",
    "    summary = set()\n",
    "    texts = tokenize.sent_tokenize(reviews)\n",
    "    for sentence in texts:\n",
    "        sentence = sentence.lower()\n",
    "        for word in list_of_keywords:\n",
    "            if word in sentence:\n",
    "                # Remove HTML.\n",
    "                post_text = BeautifulSoup(sentence).get_text()\n",
    "\n",
    "                # Remove non-letters.\n",
    "                letters_only = ' '.join(re.findall(r\"[A-zâ€™]+\",post_text))\n",
    "\n",
    "                # Convert to lower case, split into individual words.\n",
    "                words = letters_only.lower().split()\n",
    "\n",
    "                #convert the stopwords to a set.\n",
    "                stops = set(stop_words)\n",
    "\n",
    "                # Remove stopwords.\n",
    "                meaningful_words = [w for w in words if w not in stops]\n",
    "\n",
    "                # Stemming \n",
    "                #p_stemmer = PorterStemmer()\n",
    "                #meaningful_words = [p_stemmer.stem(w) for w in meaningful_words]\n",
    "\n",
    "                #Lemmatize\n",
    "                lemmatizer = WordNetLemmatizer()\n",
    "                meaningful_words = [lemmatizer.lemmatize(word) for word in meaningful_words]\n",
    "\n",
    "                cleaned_sentence = (\" \".join(meaningful_words))\n",
    "                \n",
    "                summary.add(cleaned_sentence)\n",
    "                \n",
    "    return list(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_sentiments (summarised_reviews):\n",
    "    \"\"\"\n",
    "    extract features by searching for sentences with keywords defined \n",
    "    and predicting sentiments of each sentence using vader \n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    summarised_reviews: a string of words (reviews that have been cleaned)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (sentiment score, keyword)\n",
    "    \"\"\"\n",
    "    list_of_keywords = ['camera','screen','battery','simcard','touchscreen','fingerprint',\n",
    "                        'ringtones','charger']\n",
    "    summary = set()\n",
    "    \n",
    "    for cleaned_sentence in summarised_reviews:\n",
    "        \n",
    "        for word in list_of_keywords:\n",
    "            if word in cleaned_sentence:\n",
    "                score = analyser.polarity_scores(cleaned_sentence)\n",
    "                compound = score['compound']\n",
    "\n",
    "                if compound >= 0.05:\n",
    "                    sentiment_score = 5\n",
    "                elif compound >= -0.05:\n",
    "                    sentiment_score = 3\n",
    "                else:\n",
    "                    sentiment_score = 1\n",
    "\n",
    "                summary.add((sentiment_score,word))\n",
    "    return list(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function to clean and process sentences with keywords\n",
    "new_reviews['summary'] = new_reviews['reviews'].apply(summarise_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function to shortlist sentences that contain keywords\n",
    "new_reviews['sentences_with_keywords'] = new_reviews['reviews'].apply(sentences_with_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function that extract feature and predict sentiments using vader\n",
    "new_reviews['vader_analysis'] = new_reviews['summary'].apply(features_and_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows with empty list - these are reviews that contain no keywords/features\n",
    "new_reviews[\"filter summary\"] = new_reviews['summary'].apply(lambda x: x != [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter only the reviews with keywords\n",
    "new_reviews = new_reviews[new_reviews[\"filter summary\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22041, 25)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm the shape\n",
    "new_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the index\n",
    "new_reviews.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the dataframe that has been updated with new columns to csv\n",
    "#new_reviews.to_csv('../data/cleaned_combined_data_with_keywords.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will also try to train a model using Logistic Regression Classifier. The approach would be to train the model with overall rating and then use the trained model to do sentiment predictions on sentences that contain keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the first notebook, class 0 corresponds to negative sentiment, while class 1 corresponds to neutral sentiment and class 2 corresponds to positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the classes in the target variable\n",
    "new_reviews['multi_class_sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature and target variable\n",
    "X = new_reviews['cleaned_reviews']\n",
    "y = new_reviews['multi_class_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_test_split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 42,\n",
    "                                                    stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.633575\n",
       "0    0.269933\n",
       "1    0.096491\n",
       "Name: multi_class_sentiment, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.634\n"
     ]
    }
   ],
   "source": [
    "#finding the baseline accuracy\n",
    "baseline_model = y_train.value_counts(normalize=True)\n",
    "baseline_accuracy = round(baseline_model[2],3)\n",
    "\n",
    "print(f\"Baseline accuracy: {baseline_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 63.4% accuracy if we predict everything as class 2 which corresponds to positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u)...\n",
       "                                                           solver='liblinear',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.95],\n",
       "                         'cvec__max_features': [3000, 4000, 5000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'lr__C': [0.01, 0.1, 1], 'lr__penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate the pipeline\n",
    "lr_cvec_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr',LogisticRegression(random_state=42,solver='liblinear', max_iter=10000))\n",
    "])\n",
    "\n",
    "#create hyperparameters for gridsearch\n",
    "lr_cvec_params = {\n",
    "    'cvec__max_features': [3000,4000,5000],\n",
    "    'cvec__min_df':[2,3],\n",
    "    'cvec__max_df':[0.9,0.95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "    'lr__C':[0.01,0.1,1],\n",
    "    'lr__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "lr_cvec_gs = GridSearchCV(lr_cvec_pipe, # what object are we optimizing?\n",
    "                  param_grid=lr_cvec_params , # what parameters values are we searching?\n",
    "                  cv=5,\n",
    "                 n_jobs=-1,verbose=1) \n",
    "\n",
    "#fit the model\n",
    "lr_cvec_gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CVEC Train Accuracy Score: 0.888\n",
      "Logistic Regression CVEC Test Accuracy Score: 0.834\n"
     ]
    }
   ],
   "source": [
    "training_accuracy_score = round(lr_cvec_gs.score(X_train,y_train),3)\n",
    "testing_accuracy_score = round(lr_cvec_gs.score(X_test,y_test),3)\n",
    "\n",
    "print(f\"Logistic Regression CVEC Train Accuracy Score: {training_accuracy_score}\")\n",
    "print(f\"Logistic Regression CVEC Test Accuracy Score: {testing_accuracy_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 83.4% accuracy score on the test set in predicting overall rating of each review. However, that is not our final goal. We eventually want to use the model to predict every sentence that contains the keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the model \n",
    "import pickle\n",
    "filename= '../data/logreg_3classes.pkl'\n",
    "pickle.dump(lr_cvec_gs,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on Feature Level with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 'battery'), (5, 'screen')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logreg_classification (reviews):\n",
    "     \"\"\"\n",
    "    extract features by searching for sentences with keywords defined \n",
    "    and predicting sentiments of each sentence using logistic regression\n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    summarised_reviews: a string of words (reviews that have been cleaned)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (sentiment score, keyword)\n",
    "    \"\"\"\n",
    "    list_of_keywords = ['camera','screen','battery','simcard','touchscreen','fingerprint','fingerprints',\n",
    "                        'ringtones','charger']\n",
    "    summary = set()\n",
    "    pred = lr_cvec_gs.predict(reviews)\n",
    "    \n",
    "    predicted_ratings= []\n",
    "    for score in pred:\n",
    "        if float(score) == 2.0:\n",
    "            rating = 5\n",
    "            predicted_ratings.append(rating)\n",
    "        elif float(score) == 1.0:\n",
    "            rating = 3\n",
    "            predicted_ratings.append(rating)\n",
    "        else:\n",
    "            rating = 1\n",
    "            predicted_ratings.append(rating)\n",
    "    \n",
    "    \n",
    "    for i,cleaned_sentence in enumerate(reviews):        \n",
    "        for word in list_of_keywords:\n",
    "            if word in cleaned_sentence:\n",
    "                summary.add((predicted_ratings[i],word))\n",
    "                \n",
    "    \n",
    "    return list(summary)\n",
    "logreg_classification (new_reviews['summary'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the function to the dataframe \n",
    "new_reviews['logreg_pred'] = new_reviews['summary'].apply(logreg_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will also use a state-of-the-art technique called Bidirectional Encoder Representations. BERT was published by researchers at Google AI Language in 2018. It has caused a stir in the NLP community as its algorithm is able to look at text data from left to right and right to left instead of the usual left to right way. Hence, this will allow the model to learn **the context of the text data better.**\n",
    "\n",
    "The challenge with the previous two models above (VADER and Logistic Regression) is that they are unable to detect negation word in sentences. Hence, simple sentence like \"not good\" is often predicted to have positive sentiment instead of negative. This point will be further elaborated in notebook 5 when we do a comparison of the 3 models. BERT shows superiority in reading the context of the sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As BERT is a pre-trained model, we will not train the model. However, in order to use BERT, fine-tuning is required so that BERT is able to fine-tune its predictions to the context of our project. The fine-tuning of BERT requires quite a huge computational power, hence I have done fine-tuning using the GPU resources on Google Colab. The notebook to fine-tune BERT is called 5_fine_tuning_of_BERT_model (Notebook 5). Over here, we will prepare the validation set to do a quick evaluation of BERT performance by using accuracy score. We will load the fine-tuned BERT model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed to ensure reproducibility\n",
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_reviews['multi_class_sentiment'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split \n",
    "X_train, X_val, y_train, y_val = train_test_split(new_reviews.index.values,\n",
    "                                                  new_reviews.multi_class_sentiment.values,\n",
    "                                                  test_size = 0.25,\n",
    "                                                  random_state= 42,\n",
    "                                                  stratify=new_reviews.multi_class_sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16530,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5511,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty column\n",
    "new_reviews['data_type'] = ['not_set']*new_reviews.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label the rows with train or val\n",
    "new_reviews.loc[X_train, 'data_type'] = 'train'\n",
    "new_reviews.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>verified</th>\n",
       "      <th>review_title</th>\n",
       "      <th>body</th>\n",
       "      <th>helpfulVotes</th>\n",
       "      <th>brand</th>\n",
       "      <th>item_title</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>multi_class_sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>summary</th>\n",
       "      <th>sentences_with_keywords</th>\n",
       "      <th>features_and_sentiments</th>\n",
       "      <th>filter summary</th>\n",
       "      <th>logreg_pred</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0000SX2UC</td>\n",
       "      <td>Janet</td>\n",
       "      <td>3</td>\n",
       "      <td>October 11, 2005</td>\n",
       "      <td>False</td>\n",
       "      <td>Def not best, but not worst</td>\n",
       "      <td>I had the Samsung A600 for awhile which is absolute doo doo. You can read my review on it and detect my rage at the stupid thing. It finally died on me so I used this Nokia phone I bought in a garage sale for $1. I wonder y she sold it so cheap?... Bad: ===&gt; I hate the menu. It takes forever to get to what you want because you have to scroll endlessly. Usually phones have numbered categories so u can simply press the # and get where you want to go. ===&gt; It's a pain to put it on silent or vibrate. If you're in class and it rings, you have to turn it off immediately. There's no fast way to silence the damn thing. Always remember to put it on silent! I learned that the hard way. ===&gt; It's so true about the case. It's a mission to get off and will break ur nails in the process. Also, you'll damage the case each time u try. For some reason the phone started giving me problems once I did succeed in opening it. ===&gt; Buttons could be a bit bigger. Vibration could be stronger. Good: ===&gt; Reception is not too shabby. I was using it in the elevator which is a remarkable feat considering my old phone would lose service by simply putting it in my pocket. ===&gt; Compared to my old Samsung, this phone works quite well. The ring tones are loud enough to hear and the phone actually charges quickly and has great battery life. It doesn't heat up like a potatoe in the oven either during long phone convos. ===&gt; Nice bright, large screen. ===&gt; Cute ways to customize it. Scroll bar can be set to purple, pink, aqua, orange, etc. Overall: Okay phone. It serves its purpose but definitely pales in comparison to these new phones coming out from Sprint. Why get so so when you can get great?</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>Dual-Band / Tri-Mode Sprint PCS Phone w/ Voice Activated Dialing &amp; Bright White Backlit Screen</td>\n",
       "      <td>...</td>\n",
       "      <td>333</td>\n",
       "      <td>def best worst samsung awhile absolute doo doo read review detect rage stupid thing finally died used nokia bought garage sale wonder sold cheap bad hate menu take forever get want scroll endlessly usually phone numbered category u simply press get want go pain put silent vibrate class ring turn immediately fast way silence damn thing always remember put silent learned hard way true case mission get break ur nail process also damage case time u try reason started giving problem succeed opening button could bit bigger vibration could stronger good reception shabby using elevator remarkable feat considering old would lose service simply putting pocket compared old samsung work quite well ring tone loud enough hear actually charge quickly great battery life heat like potatoe oven either long convos nice bright large screen cute way customize scroll bar set purple pink aqua orange etc overall okay serf purpose definitely pale comparison new phone coming sprint get get great</td>\n",
       "      <td>1</td>\n",
       "      <td>['def', 'best', 'worst', 'samsung', 'awhile', 'absolute', 'doo', 'doo', 'read', 'review', 'detect', 'rage', 'stupid', 'thing', 'finally', 'died', 'used', 'nokia', 'bought', 'garage', 'sale', 'wonder', 'sold', 'cheap', 'bad', 'hate', 'menu', 'take', 'forever', 'get', 'want', 'scroll', 'endlessly', 'usually', 'phone', 'numbered', 'category', 'u', 'simply', 'press', 'get', 'want', 'go', 'pain', 'put', 'silent', 'vibrate', 'class', 'ring', 'turn', 'immediately', 'fast', 'way', 'silence', 'damn', 'thing', 'always', 'remember', 'put', 'silent', 'learned', 'hard', 'way', 'true', 'case', 'mission', 'get', 'break', 'ur', 'nail', 'process', 'also', 'damage', 'case', 'time', 'u', 'try', 'reason', 'started', 'giving', 'problem', 'succeed', 'opening', 'button', 'could', 'bit', 'bigger', 'vibration', 'could', 'stronger', 'good', 'reception', 'shabby', 'using', 'elevator', 'remarkable', 'feat', 'considering', 'old', 'would', 'lose', 'service', 'simply', 'putting', 'pocket', 'compared', 'old', 'samsung', 'work', 'quite', 'well', 'ring', 'tone', 'loud', 'enough', 'hear', 'actually', 'charge', 'quickly', 'great', 'battery', 'life', 'heat', 'like', 'potatoe', 'oven', 'either', 'long', 'convos', 'nice', 'bright', 'large', 'screen', 'cute', 'way', 'customize', 'scroll', 'bar', 'set', 'purple', 'pink', 'aqua', 'orange', 'etc', 'overall', 'okay', 'serf', 'purpose', 'definitely', 'pale', 'comparison', 'new', 'phone', 'coming', 'sprint', 'get', 'get', 'great']</td>\n",
       "      <td>[ring tone loud enough hear phone actually charge quickly great battery life, nice bright large screen]</td>\n",
       "      <td>[the ring tones are loud enough to hear and the phone actually charges quickly and has great battery life., ===&gt; nice bright, large screen.]</td>\n",
       "      <td>[(5, battery), (5, screen)]</td>\n",
       "      <td>True</td>\n",
       "      <td>{(2, screen), (2, battery)}</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0000SX2UC</td>\n",
       "      <td>Brooke</td>\n",
       "      <td>5</td>\n",
       "      <td>December 30, 2003</td>\n",
       "      <td>False</td>\n",
       "      <td>Love This Phone</td>\n",
       "      <td>This is a great, reliable phone. I also purchased this phone after my samsung A460 died. The menu is easily comprehendable and speed dialing is available for around 300 numbers. Voice dialing is also a nice feature, but it takes longer than speed dialing. The only thing that bothers me is the games...Nokia seems to have taken snake (1 and 2) off their phones. There is a skydiving game, bowling, and tennis (like pong). The ringers are very nice, and a feature is available to choose a different ringer for each person calling. However, ringtones are not available online to download to this phone. You're pretty much stuck with what you have. There are vibrating ringtones and regular (midi) polyphonic tones. All they need are covers in a reasonable price range...</td>\n",
       "      <td>5.0</td>\n",
       "      <td></td>\n",
       "      <td>Dual-Band / Tri-Mode Sprint PCS Phone w/ Voice Activated Dialing &amp; Bright White Backlit Screen</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>love great reliable also purchased samsung died menu easily comprehendable speed dialing available around number voice dialing also nice feature take longer speed dialing thing bother game nokia seems taken snake phone skydiving game bowling tennis like pong ringer nice feature available choose different ringer person calling however ringtones available online download pretty much stuck vibrating ringtones regular midi polyphonic tone need cover reasonable price range</td>\n",
       "      <td>2</td>\n",
       "      <td>['love', 'great', 'reliable', 'also', 'purchased', 'samsung', 'died', 'menu', 'easily', 'comprehendable', 'speed', 'dialing', 'available', 'around', 'number', 'voice', 'dialing', 'also', 'nice', 'feature', 'take', 'longer', 'speed', 'dialing', 'thing', 'bother', 'game', 'nokia', 'seems', 'taken', 'snake', 'phone', 'skydiving', 'game', 'bowling', 'tennis', 'like', 'pong', 'ringer', 'nice', 'feature', 'available', 'choose', 'different', 'ringer', 'person', 'calling', 'however', 'ringtones', 'available', 'online', 'download', 'pretty', 'much', 'stuck', 'vibrating', 'ringtones', 'regular', 'midi', 'polyphonic', 'tone', 'need', 'cover', 'reasonable', 'price', 'range']</td>\n",
       "      <td>[vibrating ringtones regular midi polyphonic tone, however ringtones not available online download phone]</td>\n",
       "      <td>[however, ringtones are not available online to download to this phone., there are vibrating ringtones and regular (midi) polyphonic tones.]</td>\n",
       "      <td>[(3, ringtones)]</td>\n",
       "      <td>True</td>\n",
       "      <td>{(2, ringtones)}</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin    name  rating               date  verified  \\\n",
       "0  B0000SX2UC   Janet       3   October 11, 2005     False   \n",
       "1  B0000SX2UC  Brooke       5  December 30, 2003     False   \n",
       "\n",
       "                  review_title  \\\n",
       "0  Def not best, but not worst   \n",
       "1              Love This Phone   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       body  \\\n",
       "0  I had the Samsung A600 for awhile which is absolute doo doo. You can read my review on it and detect my rage at the stupid thing. It finally died on me so I used this Nokia phone I bought in a garage sale for $1. I wonder y she sold it so cheap?... Bad: ===> I hate the menu. It takes forever to get to what you want because you have to scroll endlessly. Usually phones have numbered categories so u can simply press the # and get where you want to go. ===> It's a pain to put it on silent or vibrate. If you're in class and it rings, you have to turn it off immediately. There's no fast way to silence the damn thing. Always remember to put it on silent! I learned that the hard way. ===> It's so true about the case. It's a mission to get off and will break ur nails in the process. Also, you'll damage the case each time u try. For some reason the phone started giving me problems once I did succeed in opening it. ===> Buttons could be a bit bigger. Vibration could be stronger. Good: ===> Reception is not too shabby. I was using it in the elevator which is a remarkable feat considering my old phone would lose service by simply putting it in my pocket. ===> Compared to my old Samsung, this phone works quite well. The ring tones are loud enough to hear and the phone actually charges quickly and has great battery life. It doesn't heat up like a potatoe in the oven either during long phone convos. ===> Nice bright, large screen. ===> Cute ways to customize it. Scroll bar can be set to purple, pink, aqua, orange, etc. Overall: Okay phone. It serves its purpose but definitely pales in comparison to these new phones coming out from Sprint. Why get so so when you can get great?   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          This is a great, reliable phone. I also purchased this phone after my samsung A460 died. The menu is easily comprehendable and speed dialing is available for around 300 numbers. Voice dialing is also a nice feature, but it takes longer than speed dialing. The only thing that bothers me is the games...Nokia seems to have taken snake (1 and 2) off their phones. There is a skydiving game, bowling, and tennis (like pong). The ringers are very nice, and a feature is available to choose a different ringer for each person calling. However, ringtones are not available online to download to this phone. You're pretty much stuck with what you have. There are vibrating ringtones and regular (midi) polyphonic tones. All they need are covers in a reasonable price range...   \n",
       "\n",
       "  helpfulVotes brand  \\\n",
       "0          1.0         \n",
       "1          5.0         \n",
       "\n",
       "                                                                                       item_title  \\\n",
       "0  Dual-Band / Tri-Mode Sprint PCS Phone w/ Voice Activated Dialing & Bright White Backlit Screen   \n",
       "1  Dual-Band / Tri-Mode Sprint PCS Phone w/ Voice Activated Dialing & Bright White Backlit Screen   \n",
       "\n",
       "   ... word_count  \\\n",
       "0  ...        333   \n",
       "1  ...        134   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            cleaned_reviews  \\\n",
       "0  def best worst samsung awhile absolute doo doo read review detect rage stupid thing finally died used nokia bought garage sale wonder sold cheap bad hate menu take forever get want scroll endlessly usually phone numbered category u simply press get want go pain put silent vibrate class ring turn immediately fast way silence damn thing always remember put silent learned hard way true case mission get break ur nail process also damage case time u try reason started giving problem succeed opening button could bit bigger vibration could stronger good reception shabby using elevator remarkable feat considering old would lose service simply putting pocket compared old samsung work quite well ring tone loud enough hear actually charge quickly great battery life heat like potatoe oven either long convos nice bright large screen cute way customize scroll bar set purple pink aqua orange etc overall okay serf purpose definitely pale comparison new phone coming sprint get get great   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  love great reliable also purchased samsung died menu easily comprehendable speed dialing available around number voice dialing also nice feature take longer speed dialing thing bother game nokia seems taken snake phone skydiving game bowling tennis like pong ringer nice feature available choose different ringer person calling however ringtones available online download pretty much stuck vibrating ringtones regular midi polyphonic tone need cover reasonable price range   \n",
       "\n",
       "  multi_class_sentiment  \\\n",
       "0                     1   \n",
       "1                     2   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                tokens  \\\n",
       "0  ['def', 'best', 'worst', 'samsung', 'awhile', 'absolute', 'doo', 'doo', 'read', 'review', 'detect', 'rage', 'stupid', 'thing', 'finally', 'died', 'used', 'nokia', 'bought', 'garage', 'sale', 'wonder', 'sold', 'cheap', 'bad', 'hate', 'menu', 'take', 'forever', 'get', 'want', 'scroll', 'endlessly', 'usually', 'phone', 'numbered', 'category', 'u', 'simply', 'press', 'get', 'want', 'go', 'pain', 'put', 'silent', 'vibrate', 'class', 'ring', 'turn', 'immediately', 'fast', 'way', 'silence', 'damn', 'thing', 'always', 'remember', 'put', 'silent', 'learned', 'hard', 'way', 'true', 'case', 'mission', 'get', 'break', 'ur', 'nail', 'process', 'also', 'damage', 'case', 'time', 'u', 'try', 'reason', 'started', 'giving', 'problem', 'succeed', 'opening', 'button', 'could', 'bit', 'bigger', 'vibration', 'could', 'stronger', 'good', 'reception', 'shabby', 'using', 'elevator', 'remarkable', 'feat', 'considering', 'old', 'would', 'lose', 'service', 'simply', 'putting', 'pocket', 'compared', 'old', 'samsung', 'work', 'quite', 'well', 'ring', 'tone', 'loud', 'enough', 'hear', 'actually', 'charge', 'quickly', 'great', 'battery', 'life', 'heat', 'like', 'potatoe', 'oven', 'either', 'long', 'convos', 'nice', 'bright', 'large', 'screen', 'cute', 'way', 'customize', 'scroll', 'bar', 'set', 'purple', 'pink', 'aqua', 'orange', 'etc', 'overall', 'okay', 'serf', 'purpose', 'definitely', 'pale', 'comparison', 'new', 'phone', 'coming', 'sprint', 'get', 'get', 'great']   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ['love', 'great', 'reliable', 'also', 'purchased', 'samsung', 'died', 'menu', 'easily', 'comprehendable', 'speed', 'dialing', 'available', 'around', 'number', 'voice', 'dialing', 'also', 'nice', 'feature', 'take', 'longer', 'speed', 'dialing', 'thing', 'bother', 'game', 'nokia', 'seems', 'taken', 'snake', 'phone', 'skydiving', 'game', 'bowling', 'tennis', 'like', 'pong', 'ringer', 'nice', 'feature', 'available', 'choose', 'different', 'ringer', 'person', 'calling', 'however', 'ringtones', 'available', 'online', 'download', 'pretty', 'much', 'stuck', 'vibrating', 'ringtones', 'regular', 'midi', 'polyphonic', 'tone', 'need', 'cover', 'reasonable', 'price', 'range']   \n",
       "\n",
       "                                                                                                     summary  \\\n",
       "0    [ring tone loud enough hear phone actually charge quickly great battery life, nice bright large screen]   \n",
       "1  [vibrating ringtones regular midi polyphonic tone, however ringtones not available online download phone]   \n",
       "\n",
       "                                                                                                                        sentences_with_keywords  \\\n",
       "0  [the ring tones are loud enough to hear and the phone actually charges quickly and has great battery life., ===> nice bright, large screen.]   \n",
       "1  [however, ringtones are not available online to download to this phone., there are vibrating ringtones and regular (midi) polyphonic tones.]   \n",
       "\n",
       "       features_and_sentiments  filter summary                  logreg_pred  \\\n",
       "0  [(5, battery), (5, screen)]            True  {(2, screen), (2, battery)}   \n",
       "1             [(3, ringtones)]            True             {(2, ringtones)}   \n",
       "\n",
       "   data_type  \n",
       "0        val  \n",
       "1      train  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>verified</th>\n",
       "      <th>review_title</th>\n",
       "      <th>body</th>\n",
       "      <th>helpfulVotes</th>\n",
       "      <th>brand</th>\n",
       "      <th>item_title</th>\n",
       "      <th>url</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>multi_class_sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>summary</th>\n",
       "      <th>sentences_with_keywords</th>\n",
       "      <th>features_and_sentiments</th>\n",
       "      <th>filter summary</th>\n",
       "      <th>logreg_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>...</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>...</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>...</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>...</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>...</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>...</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>...</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "      <td>2754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>...</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>...</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "      <td>7719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>...</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "      <td>2615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  asin  name  date  verified  review_title  body  \\\n",
       "rating data_type                                                   \n",
       "1      train      3049  3049  3049      3049          3049  3049   \n",
       "       val        1035  1035  1035      1035          1035  1035   \n",
       "2      train      1413  1413  1413      1413          1413  1413   \n",
       "       val         452   452   452       452           452   452   \n",
       "3      train      1595  1595  1595      1595          1595  1595   \n",
       "       val         532   532   532       532           532   532   \n",
       "4      train      2754  2754  2754      2754          2754  2754   \n",
       "       val         877   877   877       877           877   877   \n",
       "5      train      7719  7719  7719      7719          7719  7719   \n",
       "       val        2615  2615  2615      2615          2615  2615   \n",
       "\n",
       "                  helpfulVotes  brand  item_title   url  ...  reviews  \\\n",
       "rating data_type                                         ...            \n",
       "1      train              3049   3049        3049  3049  ...     3049   \n",
       "       val                1035   1035        1035  1035  ...     1035   \n",
       "2      train              1413   1413        1413  1413  ...     1413   \n",
       "       val                 452    452         452   452  ...      452   \n",
       "3      train              1595   1595        1595  1595  ...     1595   \n",
       "       val                 532    532         532   532  ...      532   \n",
       "4      train              2754   2754        2754  2754  ...     2754   \n",
       "       val                 877    877         877   877  ...      877   \n",
       "5      train              7719   7719        7719  7719  ...     7719   \n",
       "       val                2615   2615        2615  2615  ...     2615   \n",
       "\n",
       "                  word_count  cleaned_reviews  multi_class_sentiment  tokens  \\\n",
       "rating data_type                                                               \n",
       "1      train            3049             3049                   3049    3049   \n",
       "       val              1035             1035                   1035    1035   \n",
       "2      train            1413             1413                   1413    1413   \n",
       "       val               452              452                    452     452   \n",
       "3      train            1595             1595                   1595    1595   \n",
       "       val               532              532                    532     532   \n",
       "4      train            2754             2754                   2754    2754   \n",
       "       val               877              877                    877     877   \n",
       "5      train            7719             7719                   7719    7719   \n",
       "       val              2615             2615                   2615    2615   \n",
       "\n",
       "                  summary  sentences_with_keywords  features_and_sentiments  \\\n",
       "rating data_type                                                              \n",
       "1      train         3049                     3049                     3049   \n",
       "       val           1035                     1035                     1035   \n",
       "2      train         1413                     1413                     1413   \n",
       "       val            452                      452                      452   \n",
       "3      train         1595                     1595                     1595   \n",
       "       val            532                      532                      532   \n",
       "4      train         2754                     2754                     2754   \n",
       "       val            877                      877                      877   \n",
       "5      train         7719                     7719                     7719   \n",
       "       val           2615                     2615                     2615   \n",
       "\n",
       "                  filter summary  logreg_pred  \n",
       "rating data_type                               \n",
       "1      train                3049         3049  \n",
       "       val                  1035         1035  \n",
       "2      train                1413         1413  \n",
       "       val                   452          452  \n",
       "3      train                1595         1595  \n",
       "       val                   532          532  \n",
       "4      train                2754         2754  \n",
       "       val                   877          877  \n",
       "5      train                7719         7719  \n",
       "       val                  2615         2615  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check to ensure that the train and val are well represented since we have stratified it\n",
    "new_reviews.groupby(['rating', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the data in a format that is readable by BERT\n",
    "#since we are not doing fine-tuning of the train data here\n",
    "#we will only prepare the validation data for evaluation\n",
    "#the full-fine tuning process including tokening and dataloader \n",
    "#of train dataset is available in notebook 5\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    new_reviews[new_reviews.data_type=='val'].reviews.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val= torch.tensor(new_reviews[new_reviews.data_type=='val'].multi_class_sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data for BERT input\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5511"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up BERT Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the pre-trained model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library\n",
    "from torch.utils.data import DataLoader, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining batchsize\n",
    "batch_size = 32\n",
    "\n",
    "#final processing of data input\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "     \"\"\"\n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    predictions: predicted target variables\n",
    "    labels: actual target variables\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy per class and total accuracy \n",
    "    \"\"\"\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    correct_pred = 0\n",
    "    total_count = 0\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "        \n",
    "        correct_pred = correct_pred + len(y_preds[y_preds==label])\n",
    "        total_count = total_count + len(y_true)\n",
    "        \n",
    "    print(f'Total Accuracy:{correct_pred/total_count}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    dataloader_val: the validation set that has been processed \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    validation loss, predictions of target variable and actual target variable values \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=3,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "#to make sure that the model parameter is connected to the right tensor depending on device used\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the model\n",
    "model.load_state_dict(torch.load('../data/finetuned_BERT_epoch_2_3classes.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f9517883ca4476ad95d65a4f01e872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model \n",
    "\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I did not save the widget state hence the progress bar above is not displaying correctly. If the cell is run again, the progress bar should show. However, the cell above takes about 2 hours to run on my computer. Hence, I will not run it again for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "Accuracy: 1374/1487\n",
      "\n",
      "Class: 1\n",
      "Accuracy: 93/532\n",
      "\n",
      "Class: 2\n",
      "Accuracy: 3296/3492\n",
      "\n",
      "Total Accuracy:0.8642714570858283\n"
     ]
    }
   ],
   "source": [
    "#calculate the accuracy using the pre-defined function above\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT gives a slightly better accuracy score than Logistic Regression in sentiment predictions of the overall rating. BERT accuracy score on validation set is 86.4% while Logistic Regression gave an accuracy score of 83.4% on validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Feature Level with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section follows the same steps as the predictions of validation set above. However, instead of predicting an overall rating, this section will extract the feature of each review and predict its sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Tokenizer and Encoding Data by Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1.0, 'battery'),\n",
       " (1.0, 'camera'),\n",
       " (5.0, 'battery'),\n",
       " (5.0, 'camera'),\n",
       " (5.0, 'ringtones'),\n",
       " (5.0, 'screen')}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bert_sentiments (summarised_reviews):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameter\n",
    "    ----------\n",
    "    summarised_reviews: string of words -- in this case will feed it \n",
    "    with sentences that contain keywords\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (predicted rating, feature) \n",
    "    \"\"\"\n",
    "    list_of_keywords = ['camera','screen','battery','simcard','touchscreen','fingerprint','fingerprints',\n",
    "                        'ringtones','charger']\n",
    "    \n",
    "    summary = set()\n",
    "    \n",
    "    encoded_data_features = tokenizer.batch_encode_plus(\n",
    "    summarised_reviews, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "    input_ids_features = encoded_data_features['input_ids']\n",
    "    attention_masks_features = encoded_data_features['attention_mask']\n",
    "    #labels_features = torch.tensor(df[df.data_type=='val'].label.values)\n",
    "\n",
    "    dataset_features = TensorDataset(input_ids_features, attention_masks_features)\n",
    "\n",
    "    dataloader_features = DataLoader(dataset_features , \n",
    "                                       sampler=SequentialSampler(dataset_features ), \n",
    "                                       batch_size=batch_size)\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    for batch in dataloader_features:\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                     }\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        \n",
    "    \n",
    "    rating_score = torch.argmax(outputs[0],dim=1)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        predicted_ratings = []\n",
    "\n",
    "        for score in rating_score:\n",
    "            if float(score) == 2.0:\n",
    "                rating = 5\n",
    "                predicted_ratings.append(rating)\n",
    "            elif float(score) == 1.0:\n",
    "                rating = 3\n",
    "                predicted_ratings.append(rating)\n",
    "            else:\n",
    "                rating = 1\n",
    "                predicted_ratings.append(rating)\n",
    "\n",
    "        for i,cleaned_sentence in enumerate(summarised_reviews):        \n",
    "            for word in list_of_keywords:\n",
    "                if word in cleaned_sentence:\n",
    "                    summary.add((float(predicted_ratings[i]),word))\n",
    "    except:\n",
    "        summary.add(np.nan)\n",
    "        \n",
    "                \n",
    "    \n",
    "    return summary\n",
    "\n",
    "\n",
    "#tried it on one review to make sure it works\n",
    "bert_sentiments(new_reviews.sentences_with_keywords.values[5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elisenerissa/opt/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4318f4da7fb4d439f4840e5f511a1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22041.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#applying function above to the dataframe to extract feature and predict sentiments with bert\n",
    "new_reviews['bert_analysis'] = new_reviews['sentences_with_keywords'].progress_apply(bert_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I did not save the widget state hence the progress bar above is not displaying correctly. If the cell is run again, the progress bar should show. However, the cell above takes about 2 hours to run on my computer. Hence, I will not run it again for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the data type to list so that the data type is consistent with vader predictions\n",
    "new_reviews['bert_analysis'] = new_reviews['bert_analysis'].map(lambda x:list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the dataframe to pickle file so preserve the datatypes\n",
    "new_reviews.to_pickle(\"../data/reviews_with_feature_sentiments.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
